{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic detection of TLE events based on deep learning approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook\n",
    "In the following, we present the data and Python methods used for automatic TLE detection. Here is an overview of the python notebook:\n",
    "\n",
    "1. Environment set-up\n",
    "2. Data preprocessing\n",
    "3. YOLOv5 \n",
    "    - clone repo\n",
    "    - select model \n",
    "4. Train model\n",
    "     - Evaluation of training\n",
    "     - Results and problems\n",
    "5. Data post-processing\n",
    "6. Detection on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required packages from your cloned repository root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone this repo and install requirements.txt dependencies, including `Python>=3.8` and `PyTorch>=1.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 11953, done.\u001b[K\n",
      "remote: Total 11953 (delta 0), reused 0 (delta 0), pack-reused 11953\u001b[K\n",
      "Receiving objects: 100% (11953/11953), 12.45 MiB | 17.35 MiB/s, done.\n",
      "Resolving deltas: 100% (8219/8219), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train On Custom Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.yaml` shown below, is the dataset configuration file that defines:\n",
    "\n",
    "    - an optional download command/URL for auto-downloading, \n",
    "    - a path to a directory of training images (or path to a *.txt file with a list of training images), \n",
    "    - the same for our validation images, \n",
    "    - the number of classes,\n",
    "    - a list of class names.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset.yaml](img/yaml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a pretrained model to start training from. Here we select YOLOv5s, the smallest and fastest model available. See README table for a full comparison of all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![models](img/models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model - uncomment the following code and train the model just if the satisfactory computational power is available (training took approx. 6 hours by using GPU Quadro RTX 4000)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "- `img`: input width (in pixels)\n",
    "- `rect`: rectangular training\n",
    "- `batch`: total batch size for all GPUs\n",
    "- `epochs`:\n",
    "- `data`: dataset.yaml path\n",
    "- `cfg`: path to YOLOv5s.yaml version model\n",
    "- `weights`: empty - we didn't use pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python yolov5/train.py --img 640 --rect --batch 60 --epochs 300 --data  ./dataset/tle8.yaml --cfg yolov5/models/yolov5s.yaml --save-period 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./dataset/tle8.yaml, weights=['best_model/epoch190.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.2-46-g06831aa Python-3.8.3 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/Users/vierka/Desktop/TLE_detection/yolov5/../dataset/valbatch.ca\u001b[0m\n",
      "                 Class     Images  Instances          P          R     mAP@.5 mA\n",
      "                   all         14         19      0.332      0.368      0.208     0.0357\n",
      "Speed: 3.3ms pre-process, 137.7ms inference, 0.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5/runs/val/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/val.py --weights best_model/epoch190.pt --data  ./dataset/tle8.yaml --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/000031_ARBO.jpg\" width=\"600\">\n",
    "<img src=\"img/000037_KNM.jpg\" width=\"600\">\n",
    "<img src=\"img/000102_AGO.jpg\" width=\"600\">\n",
    "<img src=\"img/022017_VAZEC.jpg\" width=\"600\">\n",
    "<img src=\"img/211014_Senec.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - some better idea? help us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detection on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argumnets:\n",
    "\n",
    "- `source`: test data\n",
    "- `weights`: path to saved model.pt\n",
    "- `iou`: NMS IoU threshold\n",
    "- `conf`: confidence threshold\n",
    "- `img`: input width\n",
    "- `save-txt`: save results to `*.txt`\n",
    "- `save-conf`: save confidences in `--save-txt` labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/detect.py --weights best_model/epoch190.pt --source dataset/test --iou 0.3 --conf 0.45 --img 640 --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
