{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic detection of TLE events based on deep learning approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook\n",
    "In the following, we present the data and Python methods used for automatic TLE detection. Here is an overview of the python notebook:\n",
    "\n",
    "1. Environment set-up\n",
    "2. Data preprocessing\n",
    "3. YOLOv5 \n",
    "    - clone repo\n",
    "    - select model \n",
    "4. Train model\n",
    "     - Evaluation of training\n",
    "     - Results and problems\n",
    "5. Data post-processing\n",
    "6. Detection on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required packages from your cloned repository root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone this repo and install requirements.txt dependencies, including `Python>=3.8` and `PyTorch>=1.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train On Custom Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.yaml` shown below, is the dataset configuration file that defines:\n",
    "\n",
    "    - an optional download command/URL for auto-downloading, \n",
    "    - a path to a directory of training images (or path to a *.txt file with a list of training images), \n",
    "    - the same for our validation images, \n",
    "    - the number of classes,\n",
    "    - a list of class names.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset.yaml](img/yaml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a pretrained model to start training from. Here we select YOLOv5s, the smallest and fastest model available. See README table for a full comparison of all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![models](img/models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model - uncomment the following code and train the model just if the satisfactory computational power is available (training took approx. 6 hours by using GPU Quadro RTX 4000)\n",
    "\n",
    "Arguments:\n",
    "\n",
    "- `img`: input width (in pixels)\n",
    "- `rect`: rectangular training\n",
    "- `batch`: total batch size for all GPUs\n",
    "- `epochs`:\n",
    "- `data`: dataset.yaml path\n",
    "- `cfg`: path to YOLOv5s.yaml version model\n",
    "- `weights`: empty - we didn't use pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python yolov5/train.py --img 640 --rect --batch 60 --epochs 300 --data  ./dataset/tle8.yaml --cfg yolov5/models/yolov5s.yaml --save-period 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/val.py --weights best_model/epoch190.pt --data  ./dataset/tle8.yaml --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/000031_ARBO.jpg\" width=\"600\">\n",
    "<img src=\"img/000037_KNM.jpg\" width=\"600\">\n",
    "<img src=\"img/000102_AGO.jpg\" width=\"600\">\n",
    "<img src=\"img/022017_VAZEC.jpg\" width=\"600\">\n",
    "<img src=\"img/211014_Senec.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - some better idea? help us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detection on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argumnets:\n",
    "\n",
    "- `source`: test data\n",
    "- `weights`: path to saved model.pt\n",
    "- `iou`: NMS IoU threshold\n",
    "- `conf`: confidence threshold\n",
    "- `img`: input width\n",
    "- `save-txt`: save results to `*.txt`\n",
    "- `save-conf`: save confidences in `--save-txt` labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 292/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220222_ARBO.jpg: 480x640 1 event, 136.8ms\n",
      "image 293/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220523_ARBO.jpg: 480x640 (no detections), 157.9ms\n",
      "image 294/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220808_ARBO.jpg: 480x640 (no detections), 110.9ms\n",
      "image 295/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220826_ARBO.jpg: 480x640 (no detections), 113.7ms\n",
      "image 296/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220829_ARBO.jpg: 480x640 (no detections), 112.9ms\n",
      "image 297/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220836_ARBO.jpg: 480x640 (no detections), 129.0ms\n",
      "image 298/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220839_VAZEC.jpg: 480x640 (no detections), 147.2ms\n",
      "image 299/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220907_ARBO.jpg: 480x640 (no detections), 138.9ms\n",
      "image 300/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220914_ARBO.jpg: 480x640 (no detections), 118.6ms\n",
      "image 301/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_220948_ARBO.jpg: 480x640 (no detections), 125.7ms\n",
      "image 302/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_221636_VAZEC.jpg: 480x640 (no detections), 128.6ms\n",
      "image 303/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_222113_VAZEC.jpg: 480x640 (no detections), 151.7ms\n",
      "image 304/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_222321_VAZEC.jpg: 480x640 (no detections), 160.8ms\n",
      "image 305/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_222746_ARBO.jpg: 480x640 (no detections), 128.4ms\n",
      "image 306/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_222746_VAZEC.jpg: 480x640 (no detections), 110.0ms\n",
      "image 307/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_223658_ARBO.jpg: 480x640 (no detections), 113.0ms\n",
      "image 308/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231252_VAZEC.jpg: 480x640 (no detections), 136.2ms\n",
      "image 309/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231314_ARBO.jpg: 480x640 (no detections), 165.1ms\n",
      "image 310/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231402_ARBO.jpg: 480x640 (no detections), 162.5ms\n",
      "image 311/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231555_ARBO.jpg: 480x640 (no detections), 119.6ms\n",
      "image 312/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231631_ARBO.jpg: 480x640 (no detections), 114.5ms\n",
      "image 313/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231742_ARBO.jpg: 480x640 (no detections), 148.2ms\n",
      "image 314/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231810_VAZEC.jpg: 480x640 (no detections), 160.1ms\n",
      "image 315/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231914_ARBO.jpg: 480x640 (no detections), 163.0ms\n",
      "image 316/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_231927_ARBO.jpg: 480x640 (no detections), 141.3ms\n",
      "image 317/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_232049_ARBO.jpg: 480x640 (no detections), 184.1ms\n",
      "image 318/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_233203_AGO.jpg: 480x640 (no detections), 169.5ms\n",
      "image 319/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_233203_VAZEC.jpg: 480x640 (no detections), 152.9ms\n",
      "image 320/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_233829_VAZEC.jpg: 480x640 (no detections), 163.4ms\n",
      "image 321/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_233917_AGO.jpg: 480x640 (no detections), 133.7ms\n",
      "image 322/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_233917_ARBO.jpg: 480x640 (no detections), 122.2ms\n",
      "image 323/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_234020_ARBO.jpg: 480x640 (no detections), 129.1ms\n",
      "image 324/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_234020_VAZEC.jpg: 480x640 (no detections), 150.0ms\n",
      "image 325/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_234242_ARBO.jpg: 480x640 (no detections), 133.4ms\n",
      "image 326/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_234948_VAZEC.jpg: 480x640 (no detections), 194.1ms\n",
      "image 327/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_235114_AGO.jpg: 480x640 (no detections), 138.8ms\n",
      "image 328/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_235408_ARBO.jpg: 480x640 (no detections), 115.4ms\n",
      "image 329/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_235435_AGO.jpg: 480x640 (no detections), 147.5ms\n",
      "image 330/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_235435_ARBO.jpg: 480x640 (no detections), 136.9ms\n",
      "image 331/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_235523_ARBO.jpg: 480x640 (no detections), 108.7ms\n",
      "image 332/514 /Users/vierka/Desktop/tle_detection/dataset/test/1_235857_VAZEC.jpg: 480x640 (no detections), 116.6ms\n",
      "image 333/514 /Users/vierka/Desktop/tle_detection/dataset/test/200345_AGO.jpg: 480x640 (no detections), 111.3ms\n",
      "image 334/514 /Users/vierka/Desktop/tle_detection/dataset/test/200610_VAZEC.jpg: 480x640 (no detections), 104.3ms\n",
      "image 335/514 /Users/vierka/Desktop/tle_detection/dataset/test/201046_AGO.jpg: 480x640 (no detections), 107.5ms\n",
      "image 336/514 /Users/vierka/Desktop/tle_detection/dataset/test/201046_ARBO.jpg: 480x640 (no detections), 118.8ms\n",
      "image 337/514 /Users/vierka/Desktop/tle_detection/dataset/test/201046_VAZEC.jpg: 480x640 (no detections), 110.4ms\n",
      "image 338/514 /Users/vierka/Desktop/tle_detection/dataset/test/201619_VAZEC.jpg: 480x640 1 event, 118.5ms\n",
      "image 339/514 /Users/vierka/Desktop/tle_detection/dataset/test/202336_VAZEC.jpg: 480x640 (no detections), 127.6ms\n",
      "image 340/514 /Users/vierka/Desktop/tle_detection/dataset/test/202600_VAZEC.jpg: 480x640 (no detections), 110.0ms\n",
      "image 341/514 /Users/vierka/Desktop/tle_detection/dataset/test/202812_VAZEC.jpg: 480x640 (no detections), 114.9ms\n",
      "image 342/514 /Users/vierka/Desktop/tle_detection/dataset/test/202902_AGO.jpg: 480x640 (no detections), 126.9ms\n",
      "image 343/514 /Users/vierka/Desktop/tle_detection/dataset/test/203413_VAZEC.jpg: 480x640 1 event, 131.0ms\n",
      "image 344/514 /Users/vierka/Desktop/tle_detection/dataset/test/203833_AGO.jpg: 480x640 (no detections), 123.2ms\n",
      "image 345/514 /Users/vierka/Desktop/tle_detection/dataset/test/204026_AGO.jpg: 480x640 (no detections), 109.9ms\n",
      "image 346/514 /Users/vierka/Desktop/tle_detection/dataset/test/204033_VAZEC.jpg: 480x640 (no detections), 113.7ms\n",
      "image 347/514 /Users/vierka/Desktop/tle_detection/dataset/test/204607_VAZEC.jpg: 480x640 (no detections), 119.1ms\n",
      "image 348/514 /Users/vierka/Desktop/tle_detection/dataset/test/204629_VAZEC.jpg: 480x640 (no detections), 128.9ms\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/detect.py --weights best_model/epoch190.pt --source dataset/test --iou 0.3 --conf 0.45 --img 640 --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
